# ğŸŒ¸ Iris Dataset Classification - ML Algorithms Comparison

![Python](https://img.shields.io/badge/Python-3.7%2B-blue)
![scikit-learn](https://img.shields.io/badge/scikit--learn-ML-orange)
![Status](https://img.shields.io/badge/Status-Complete-success)
![License](https://img.shields.io/badge/License-MIT-green)

A comprehensive machine learning project comparing 7 classification algorithms on the classic Iris dataset. This repository demonstrates best practices in data science, including exploratory data analysis, model training, evaluation, and performance comparison across multiple algorithms.

## ğŸ“Š Overview

This project addresses the **multi-class classification problem** of identifying iris flower species based on physical measurements. The solution implements and evaluates 7 different machine learning algorithms, providing insights into their strengths, weaknesses, and optimal use cases.

**Problem:** Classify iris flowers into three species (Setosa, Versicolor, Virginica) using sepal and petal measurements.

**Solution:** Systematic comparison of traditional ML algorithms with comprehensive evaluation metrics and visualizations.

## ğŸ¯ Algorithms Implemented

1. **Decision Tree Classifier** - Interpretable tree-based model
2. **K-Nearest Neighbors (KNN)** - Distance-based classification
3. **Logistic Regression** - Linear probabilistic model
4. **Naive Bayes Classifier** - Probabilistic classification with independence assumption
5. **Random Forest Classifier** - Ensemble of decision trees
6. **Support Vector Machine (SVM)** - Kernel-based maximum margin classifier
7. **Gradient Boosting Classifier** - Sequential ensemble learning

## ğŸ“ Folder Structure

```
Iris-Dataset/
â”‚
â”œâ”€â”€ notebooks/                           # Jupyter notebooks for analysis
â”‚   â”œâ”€â”€ iris_decision_tree_classifier.ipynb
â”‚   â”œâ”€â”€ iris_k_nearest_neighbors.ipynb
â”‚   â”œâ”€â”€ iris_logistic_regression.ipynb
â”‚   â”œâ”€â”€ iris_naive_bayes_classifier.ipynb
â”‚   â”œâ”€â”€ iris_random_forest_classifier.ipynb
â”‚   â”œâ”€â”€ iris_support_vector_machine.ipynb
â”‚   â””â”€â”€ iris_gradient_boosting.ipynb
â”‚
â”œâ”€â”€ Iris.csv                             # Dataset file
â”œâ”€â”€ ANALYSIS.md                          # Detailed performance analysis
â”œâ”€â”€ README.md                            # Project documentation
â”œâ”€â”€ requirements.txt                     # Python dependencies
â”œâ”€â”€ .gitignore                           # Git ignore rules
â””â”€â”€ LICENSE                              # MIT License
```

## ğŸ“‹ Dataset

**Name:** [Iris Dataset](https://archive.ics.uci.edu/ml/datasets/iris)  
**Source:** UCI Machine Learning Repository  
**Size:** 150 samples (50 per class)  
**Features:** 4 numerical attributes
- Sepal Length (cm)
- Sepal Width (cm)
- Petal Length (cm)
- Petal Width (cm)

**Target Variable:** Species (3 classes - Setosa, Versicolor, Virginica)

## ğŸ† Key Results

- **Best Model:** Gradient Boosting Classifier
- **Accuracy:** ~99% on test set
- **Runner-ups:** Random Forest (98%), SVM (98%)
- **Fastest Model:** Logistic Regression (97% accuracy, lowest complexity)
- **Most Interpretable:** Decision Tree (97% accuracy, visual decision rules)

All models achieved >95% accuracy, demonstrating that the Iris dataset is well-suited for classification tasks.

## ğŸš€ Installation & Usage

### Clone Repository
```bash
git clone https://github.com/TasinAhmed2508/Iris-Dataset.git
cd Iris-Dataset
```

### Install Dependencies
```bash
pip install -r requirements.txt
```

### Run Notebooks
```bash
# Launch Jupyter
jupyter notebook

# Navigate to notebooks/ folder and open any .ipynb file
```

Each notebook contains:
- Data loading and exploration
- Model training and hyperparameter tuning
- Performance evaluation with metrics
- Visualization of results

## ğŸ› ï¸ Technologies Used

- **Python 3.7+**
- **scikit-learn** - Machine learning algorithms
- **pandas** - Data manipulation
- **numpy** - Numerical computing
- **matplotlib** - Visualization
- **seaborn** - Statistical visualization
- **Jupyter** - Interactive notebooks

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/iris-classification.git
cd iris-classification

# Install required packages
pip install -r requirements.txt
```

### Running Notebooks

Open any notebook in Jupyter:
```bash
jupyter notebook iris_decision_tree.ipynb
```

## ğŸ“ˆ Key Features

- âœ… Data loading and exploration
- âœ… Feature scaling and preprocessing
- âœ… Train-test split validation
- âœ… Model training and hyperparameter tuning
- âœ… Performance metrics (Accuracy, Precision, Recall, F1-Score)
- âœ… Confusion matrix visualization
- âœ… ROC curves and classification reports
- âœ… Feature importance analysis

## ğŸ’¡ Learning Outcomes

This project demonstrates:
- How to implement various ML algorithms from scikit-learn
- Model evaluation and comparison techniques
- Data visualization best practices
- Hyperparameter tuning strategies
- Cross-validation methods

## ğŸ“Š Results

Each notebook includes detailed performance metrics and visualizations comparing:
- Classification accuracy
- Training time
- Model complexity
- Strengths and weaknesses of each approach

## ğŸ¤ Contributing

Feel free to fork this repository and submit pull requests with improvements, additional algorithms, or enhanced visualizations.

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ“š References

- [Scikit-learn Documentation](https://scikit-learn.org/)
- [Iris Dataset on UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/iris)
- [Machine Learning Mastery](https://machinelearningmastery.com/)

---

**Last Updated:** January 2026

